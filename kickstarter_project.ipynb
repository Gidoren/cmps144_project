{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook description:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\") #white background style for seaborn plots\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics  \n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ks-projects-201801.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform some data cleaning and feature engineering. Create one-hot-encoding for  \n",
    "string labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of days between launch data and deadline\n",
    "def duration_of_project():\n",
    "    duration = []\n",
    "    \n",
    "    for launch, deadline in zip(data['launched'], data['deadline']):\n",
    "        \n",
    "        launch = (launch.split())[0]\n",
    "        launchT = [x.strip() for x in launch.split('-')]\n",
    "        deadlineT = [x.strip() for x in deadline.split('-')]\n",
    "    \n",
    "        year_diff = (int(deadlineT[0]) - int(launchT[0]))*365\n",
    "        month_diff = (int(deadlineT[1]) - int(launchT[1]))*30\n",
    "        day_diff = int(deadlineT[2]) - int(launchT[2])\n",
    "    \n",
    "        days_offset = year_diff + month_diff + day_diff\n",
    "        duration.append(days_offset)\n",
    "        \n",
    "    data['duration'] = duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add column for the duration of the project\n",
    "duration_of_project()\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting unique categories in a list\n",
    "cat = []\n",
    "print(\"hrllo)\")\n",
    "for i in data['category']:\n",
    "    if len(cat) == 0:\n",
    "        cat.append(i)\n",
    "    k = 0\n",
    "    for j in cat:\n",
    "        if j == i:\n",
    "            k = 1\n",
    "            break\n",
    "    if k==0:\n",
    "        cat.append(i)\n",
    "#creating the unique categories successful mean\n",
    "BackerMean = [0] * 160\n",
    "counter = 0\n",
    "for i in cat:\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for j in data['category']:\n",
    "        if j==cat[counter]:\n",
    "            if data['state'][count] == 'successful':\n",
    "                BackerMean[counter] += data['backers'][count]\n",
    "                total = total + 1\n",
    "        count = count + 1\n",
    "    if BackerMean[counter]!= 0:\n",
    "        BackerMean[counter] = BackerMean[counter]/total\n",
    "    BackerMean[counter] = round(BackerMean[counter])\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a Column stating a binary state on whether or not the project had reached the mean\n",
    "#of backers in its prospective category\n",
    "BackerBinary = [0] * 378661\n",
    "CategoryMean = [0] * 378661\n",
    "counter = 0\n",
    "for i in cat:\n",
    "    count = 0\n",
    "    for j in data['category']:\n",
    "        if j == i:\n",
    "            BackerBinary[count] = data['backers'][count] - BackerMean[counter]\n",
    "            CategoryMean[count] = BackerMean[counter]\n",
    "            if BackerBinary[count] < 0:\n",
    "                BackerBinary[count] = -1\n",
    "            else:\n",
    "                BackerBinary[count] = 1\n",
    "        count = count+1\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CategoryBackerMean'] = CategoryMean\n",
    "data['BackerBinary'] = BackerBinary\n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert state to -1, 1 for fail, succeed\n",
    "data['state'].replace(['canceled'], ['failed'], inplace=True)\n",
    "data['state'].replace(['failed', 'successful'], [-1, 1], inplace=True)\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()\n",
    "#how do we deal with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of categories\n",
    "print(data['category'].value_counts());\n",
    "#possible new column (popular category vs unpopular category);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['state_binary'] = data['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translate state to 0 and 1\n",
    "data['state_binary'].replace([-1, 1], [0, 1], inplace=True)\n",
    "data.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = []\n",
    "print(\"hrllo)\")\n",
    "for i in data['category']:\n",
    "    if len(cat) == 0:\n",
    "        cat.append(i)\n",
    "    k = 0\n",
    "    for j in cat:\n",
    "        if j == i:\n",
    "            k = 1\n",
    "            break\n",
    "    if k==0:\n",
    "        cat.append(i)\n",
    "\n",
    "BackerMean = [0] * 160\n",
    "counter = 0\n",
    "for i in cat:\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for j in data['category']:\n",
    "        if j==cat[counter] & int(data['state'][count]) == 1:\n",
    "            BackerMean[counter] += data['backers'][count]\n",
    "            total = total + 1\n",
    "        count = count + 1\n",
    "    BackerMean[counter] = BackerMean[counter]/total\n",
    "    print(BackerMean[counter], \" \",counter)\n",
    "    counter = counter + 1\n",
    "print(BackerMean[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['main_category'].value_counts());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['country'].value_counts());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boolean for each category. This modified table is stored in \"training\"\n",
    "#training=pd.get_dummies(data, columns=[\"main_category\"])\n",
    "#training.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apperently there are more possible states\n",
    "sns.barplot('state_binary','duration', data=data, color=\"darkturquoise\")\n",
    "plt.show()\n",
    "#Interesting to see is that the duration of unsuccessfull projects is higher. Maybe because successful projects \n",
    "#end before their initial end date. The data we got might talk about the actual end and not the initial end date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data['state'].value_counts());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SLIM DATA IS THE TABLE THAT I USE FROM THIS POINT ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#slim data drops \"undefined\", \"live\" and \"suspended\"\n",
    "slim_data = data.copy()\n",
    "indexNames = slim_data[ (slim_data['state_binary'] != 1) & (slim_data['state_binary'] != 0) ].index\n",
    "slim_data.drop(indexNames , inplace=True)\n",
    "print(slim_data['state_binary'].value_counts());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Average success rate based on category\n",
    "sns.barplot('state_binary','main_category', data=slim_data, color=\"darkturquoise\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot('state_binary','category', data=slim_data, color=\"darkturquoise\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot('state_binary','country', data=slim_data, color=\"darkturquoise\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "sns.barplot('duration', 'state_binary',data=slim_data, color=\"darkturquoise\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['duration'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducing Variance for the goal column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All goals below 1000 are updated to 1000\n",
    "#slim_data.loc[slim_data['goal'] < 1000] = 1000\n",
    "#slim_data.loc[slim_data['goal'] > 1000000] = 1000000\n",
    "#slim_data.head(1000)\n",
    "#slim_data['goal'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal histogram.\n",
    "plt.figure(figsize=(30,10))\n",
    "sns.distplot(np.log(data['goal']))\n",
    "#plt.yticks(fig.get_yticks(), fig.get_yticks() * 100000)\n",
    "#plt.ylabel('Distribution [%]', fontsize=16)\n",
    "#plt.xticks(fig.get_xticks(), fig.get_xticks() * 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arr = []\n",
    "#for i in data['currency']:\n",
    "#    exists = 0\n",
    "#    if len(Arr) == 0:\n",
    "#        Arr.append(i)\n",
    "#    else:\n",
    "#        for j in Arr:\n",
    "#            if j == i:\n",
    "#                exists = 1\n",
    "#        if exists == 0:\n",
    "#            Arr.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Create one-hot-encodings for columns: category, main-category, currency, country**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(slim_data['currency'][0])\n",
    "\n",
    "unique = []\n",
    "for curr in slim_data['currency']:\n",
    "    if curr not in unique:\n",
    "        print(curr)\n",
    "        unique.append(curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find length of name\n",
    "name_length = []\n",
    "for name in slim_data['name']:\n",
    "    try:\n",
    "        name_length.append(len(name))\n",
    "    except:\n",
    "        name_length.append(0)\n",
    "slim_data['name_len'] = name_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale down data columns\n",
    "sc = MinMaxScaler()\n",
    "\n",
    "slim_data['fit_goal'] = sc.fit_transform(slim_data[['goal']])\n",
    "slim_data['fit_name_len'] = sc.fit_transform(slim_data[['name_len']])\n",
    "slim_data['fit_duration'] = sc.fit_transform(slim_data[['duration']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training=pd.get_dummies(slim_data, columns=[\"main_category\"])\n",
    "training=pd.get_dummies(training, columns=[\"category\"])\n",
    "training=pd.get_dummies(training, columns=[\"country\"])\n",
    "training=pd.get_dummies(training, columns=[\"currency\"])\n",
    "\n",
    "y = training['state_binary']\n",
    "X = training.loc[:, 'fit_goal':]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LogisticRegression\n",
    "#logisticRegr = LogisticRegression()\n",
    "#logisticRegr.fit(X_train, y_train)\n",
    "#predictions = logisticRegr.predict(X_test)\n",
    "#score = logisticRegr.score(X_test, y_test)\n",
    "#print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build DNN\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# input layer\n",
    "model.add(Dense(200, activation='relu', input_dim = 214))\n",
    "          \n",
    "# second layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "          \n",
    "# third layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "          \n",
    "# fourth layer\n",
    "model.add(Dense(150, activation='relu'))\n",
    "\n",
    "# fith layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "          \n",
    "# output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the model using rmsprop opt and mse loss\n",
    "model.compile(optimizer = 'adam',  \n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_split = 0.33, \n",
    "                    epochs = 50,\n",
    "                    batch_size = 35)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "train_loss, train_acc = model.evaluate(X_train, y_train)\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Training set accuracy:', train_acc)\n",
    "print('Test set accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The history of our accuracy during training.\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The history of our cross-entropy loss during training.\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
